{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/insominiac21/Fake-News-Detector/blob/main/fake_news_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "import-libraries",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "import-libraries",
        "outputId": "42cef6aa-a783-44db-97e7-aed4341490df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.44.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.11/dist-packages (0.34.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.1)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install streamlit requests beautifulsoup4 tensorflow pillow spacy validators\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "write-app",
      "metadata": {
        "id": "write-app"
      },
      "outputs": [],
      "source": [
        "# Write the Streamlit app code to a file\n",
        "app_code = \"\"\"import streamlit as st\n",
        "import requests\n",
        "import os\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "from tensorflow.keras.models import load_model\n",
        "from PIL import Image\n",
        "import io\n",
        "import base64\n",
        "import spacy\n",
        "import validators\n",
        "\n",
        "def scrape_website(url):\n",
        "    Scrape the given news website for text and images.\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        return None, None\n",
        "\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extract text content\n",
        "    paragraphs = soup.find_all('p')\n",
        "    text_content = ' '.join([p.get_text() for p in paragraphs])\n",
        "\n",
        "    # Extract image URLs, excluding data URLs\n",
        "    images = [img['src'] for img in soup.find_all('img') if 'src' in img.attrs and not img['src'].startswith('data:')]\n",
        "    return text_content, images\n",
        "\n",
        "def check_text_fact(text, api_key):\n",
        "\n",
        "    endpoint = \"https://factchecktools.googleapis.com/v1alpha1/claims:search\"\n",
        "    params = {\n",
        "        \"query\": text,\n",
        "        \"key\": api_key\n",
        "    }\n",
        "    response = requests.get(endpoint, params=params)\n",
        "    if response.status_code != 200:\n",
        "        return \"Error accessing Fact Check API\", None\n",
        "\n",
        "    data = response.json()\n",
        "\n",
        "    # Debugging: Log the query and response\n",
        "    print(\"Query Sent to API:\", text)\n",
        "    print(\"API Response:\", data)\n",
        "\n",
        "    if 'claims' in data and len(data['claims']) > 0:\n",
        "        claim = data['claims'][0]\n",
        "        claim_review = claim.get('claimReview', [{}])[0]\n",
        "        textual_rating = claim_review.get('textualRating', 'Unknown')\n",
        "        review_text = claim_review.get('title', 'No additional details available')\n",
        "        return textual_rating, review_text\n",
        "    return \"No fact-check available\", None\n",
        "\n",
        "def check_image_deepfake(image_url, model)\n",
        "\n",
        "    response = requests.get(image_url, stream=True)\n",
        "    if response.status_code != 200:\n",
        "        return \"Error fetching image\"\n",
        "\n",
        "    try:\n",
        "        # Convert image to RGB format\n",
        "        img = Image.open(io.BytesIO(response.content))\n",
        "        img = img.convert('RGB')\n",
        "        img = img.resize((128, 128))\n",
        "        img_array = np.array(img) / 255.0\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        prediction = model.predict(img_array)\n",
        "        return \"Deepfake\" if prediction[0][0] > 0.5 else \"Real\"\n",
        "    except Exception:\n",
        "        return \"Invalid Image\"\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"Fake News Detector\")\n",
        "st.write(\"Enter a news article URL to check its authenticity.\")\n",
        "\n",
        "url = st.text_input(\"Enter News URL:\")\n",
        "apikey =\"Your-api-key\"\n",
        "\n",
        "if st.button(\"Check News\"):\n",
        "    if url and apikey:\n",
        "        # Validate the URL\n",
        "        if not validators.url(url) or not (url.startswith(\"http://\") or url.startswith(\"https://\")):\n",
        "            st.error(\"Invalid URL. Please enter a valid HTTP or HTTPS URL.\")\n",
        "        else:\n",
        "            st.write(\"Scraping the website...\")\n",
        "            text, images = scrape_website(url)\n",
        "\n",
        "            text_flag = False  # Initialize text_flag with a default value\n",
        "\n",
        "            if text:\n",
        "                st.subheader(\"Extracted Text\")\n",
        "                st.write(text[:500] + \"...\")\n",
        "\n",
        "                # Extract key sentences for fact-checking\n",
        "                try:\n",
        "                    nlp = spacy.load('en_core_web_sm')\n",
        "                    doc = nlp(text)\n",
        "                    key_claims = [ent.text for ent in doc.ents if ent.label_ in ['ORG', 'PERSON', 'EVENT']]\n",
        "                    key_sentences = key_claims[0] if key_claims else ' '.join(text.split('.')[:3])\n",
        "                except:\n",
        "                    key_sentences = ' '.join(text.split('.')[:3])  # Extract first 3 sentences\n",
        "\n",
        "                st.write(\"Checking text authenticity...\")\n",
        "                text_result, review_details = check_text_fact(key_sentences, apikey)\n",
        "                first_word = text_result.split()[0].rstrip('.') if text_result else \"\"  # Remove trailing period\n",
        "                third_word = review_details.split()[2].rstrip('.') if review_details and len(review_details.split()) > 2 else \"\"  # Get third word\n",
        "\n",
        "                if first_word == \"No\" or third_word == \"No\":\n",
        "                    st.write(\"Could not run text review.\")\n",
        "                    st.write(\"Reason: The webpage has not been reviewed by Google Claim Review yet.\")\n",
        "                    text_flag = None\n",
        "\n",
        "                elif first_word or third_word in {\"Half true\", \"False\", \"Mostly\", \"Misrepresentation\", \"Pants\", \"Fake\", \"Incorrect\", \"Misleading\", \"No\", \"Out\", \"Unfounded\", \"Exaggerated\", \"Debunked\"} or third_word in {\"Half true\", \"False\", \"Mostly\", \"Misrepresentation\", \"Pants\", \"Fake\", \"Incorrect\", \"Misleading\", \"No\", \"Out\", \"Unfounded\", \"Exaggerated\", \"Debunked\"}:\n",
        "                    st.write(\"🚨 This news might be FAKE!\")\n",
        "                    st.write(\"Fact Check Result: \", text_result)\n",
        "                    st.write(\"\\n\", review_details)\n",
        "                    text_flag = True\n",
        "                elif first_word == \"Not\":  # Not Transcript\n",
        "                    st.write(\"Fact Check Result: Independent assessment provided\")\n",
        "                    st.write(\"\\n\", review_details)\n",
        "                    text_flag = False\n",
        "                else:\n",
        "                    st.write(\"Fact Check Result: \", text_result)\n",
        "                    if review_details:\n",
        "                        st.write(\"Supporting Evidence: \", review_details)\n",
        "                    text_flag = False\n",
        "            else:\n",
        "                st.write(\"No text found on the page.\")\n",
        "                text_result = \"Unknown\"\n",
        "                review_details = None\n",
        "                text_flag = False  # Ensure text_flag is set even if no text is found\n",
        "\n",
        "            if images:\n",
        "                st.subheader(\"Extracted Images\")\n",
        "                model = load_model(\"deepfake_model.h5\")\n",
        "                deepfake_results = {}\n",
        "\n",
        "                for img_url in images[:3]:  # Limit to 3 images for performance\n",
        "                    result = check_image_deepfake(img_url, model)\n",
        "                    deepfake_results[img_url] = result\n",
        "                    st.image(img_url, caption=result, use_column_width=True)\n",
        "\n",
        "                # Calculate fake score\n",
        "                fake_score = sum(1 for v in deepfake_results.values() if v == \"Deepfake\") / max(len(deepfake_results), 1)\n",
        "            else:\n",
        "                st.write(\"No images found.\")\n",
        "                fake_score = 0\n",
        "\n",
        "            # Final Verdict Logic\n",
        "            st.subheader(\"Final Verdict\")\n",
        "            st.write(\"Combining text and image analysis...\")\n",
        "            # Adjust confidence calculation to prioritize text_flag\n",
        "            if text_flag is True:\n",
        "                combined_confidence = max(fake_score, 0.7)  # At least 70% if text is flagged as fake\n",
        "            elif text_flag is None:\n",
        "                combined_confidence = fake_score  # Use only fake_score if no fact-check is available\n",
        "            else:\n",
        "                combined_confidence = fake_score * 0.5  # Reduce weight of fake_score if text is real\n",
        "\n",
        "            # Display final verdict\n",
        "            if text_flag is True and combined_confidence > 0.5:\n",
        "                st.error(f\"🚨 This news might be FAKE! Confidence: {combined_confidence * 100:.2f}%\")\n",
        "            elif text_flag is None and combined_confidence > 0.5:\n",
        "                st.warning(f\"⚠️ This news might be PARTIALLY FAKE. Confidence: {combined_confidence * 100:.2f}%\")\n",
        "            elif text_flag is False or combined_confidence <= 0.5:\n",
        "                st.success(f\"✅ This news appears REAL. Confidence: {(1 - combined_confidence) * 100:.2f}%\")\n",
        "    else:\n",
        "        st.warning(\"Please enter a valid URL and API Key.\")\"\"\"\n",
        "\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(app_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "run-streamlit",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "run-streamlit",
        "outputId": "0101af9c-fb62-4ae9-d5e7-93a512f36e91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.75.0.197:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Run the Streamlit app\n",
        "!streamlit run app.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Jgk9GqHBskB"
      },
      "id": "7Jgk9GqHBskB",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
